{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9999a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager  \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb62cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_driver(url):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service= Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.get(url)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def close_driver(driver):\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "def handle_cookie_and_filters(driver):\n",
    "    try:\n",
    "        # Wait for the Sourcepoint iframe to appear\n",
    "        iframe = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.CSS_SELECTOR, \"iframe[src*='https://cdn.privacy-mgmt.com']\")\n",
    "            )\n",
    "        )\n",
    "        driver.switch_to.frame(iframe)\n",
    "        print(\"Switched into cookie consent iframe.\")\n",
    "\n",
    "        # Wait for the \"Accept all\" button to become clickable\n",
    "        cookie_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, \"//button[@title='Accept all' or @aria-label='Accept all']\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Click via JavaScript (safer than .click())\n",
    "        driver.execute_script(\"arguments[0].click();\", cookie_button)\n",
    "        print(\"Cookie consent accepted.\")\n",
    "\n",
    "        # Switch back to main content\n",
    "        driver.switch_to.default_content()\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"No cookie prompt found or timed out.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d93c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "import time, random, csv\n",
    "from datetime import datetime\n",
    "\n",
    "def scrape_articles(driver, output_csv=\"articles.csv\"):\n",
    "    all_data = []\n",
    "    cutoff_date = datetime(2025, 10, 20)\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    # Initialize CSV file with header\n",
    "    with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"Title\", \"Content\", \"Date\"])\n",
    "        writer.writeheader()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Scroll to bottom slowly to trigger lazy loading\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(random.uniform(3, 5))\n",
    "\n",
    "            # Try clicking \"Load More\" if visible\n",
    "            try:\n",
    "                load_more = driver.find_element(By.CSS_SELECTOR, \".ui-liveblog-button--load-more\")\n",
    "                if load_more.is_displayed():\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", load_more)\n",
    "                    time.sleep(1)\n",
    "                    load_more.click()\n",
    "                    print(\"Clicked 'Load More' button...\")\n",
    "                    time.sleep(random.uniform(2, 4))\n",
    "            except (NoSuchElementException, ElementClickInterceptedException):\n",
    "                pass  # no button visible — continue scrolling\n",
    "\n",
    "            # Collect all visible article elements\n",
    "            articles = driver.find_elements(By.XPATH, \"//div[@role='article']\")\n",
    "\n",
    "            for article in articles[len(all_data):]:  # only process new ones\n",
    "                try:\n",
    "                    # Get date\n",
    "                    time_elem = article.find_element(By.CSS_SELECTOR, \".ncpost-header time\")\n",
    "                    date_str = time_elem.get_attribute(\"datetime\")[:10]\n",
    "                    date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "\n",
    "                    # Title\n",
    "                    title = article.find_element(By.CLASS_NAME, \"ncpost-title\").text.strip()\n",
    "\n",
    "                    # Content\n",
    "                    paragraphs = article.find_elements(By.CSS_SELECTOR, \".ncpost-content p\")\n",
    "                    content = \" \".join([p.text.strip() for p in paragraphs])\n",
    "\n",
    "                    data = {\"Title\": title, \"Content\": content, \"Date\": date_str}\n",
    "                    all_data.append(data)\n",
    "\n",
    "                    # Save each article immediately to CSV\n",
    "                    with open(output_csv, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                        writer = csv.DictWriter(f, fieldnames=[\"Title\", \"Content\", \"Date\"])\n",
    "                        writer.writerow(data)\n",
    "\n",
    "\n",
    "                    # Stop when reaching older content\n",
    "                    if date_obj < cutoff_date:\n",
    "                        print(f\"Reached cutoff date ({date_str}). Stopping.\")\n",
    "                        return all_data\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping article due to error: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # Check if page height stopped changing (no more content)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                print(\"No more new content loaded — ending scroll.\")\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        print(f\"Scraping finished. {len(all_data)} articles saved.\")\n",
    "        return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da7e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched into cookie consent iframe.\n",
      "Cookie consent accepted.\n",
      "Clicked 'Load More' button...\n",
      "Clicked 'Load More' button...\n",
      "Reached cutoff date (2025-10-19). Stopping.\n",
      "Scraping finished. 50 articles saved.\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = 'https://www.skysports.com/football/live-blog/11095/12476234/transfer-centre-live-football-transfer-news-updates-and-rumours'\n",
    "\n",
    "def main(url):\n",
    "    driver = init_driver(url)\n",
    "    driver.maximize_window()\n",
    "    try:\n",
    "        handle_cookie_and_filters(driver)\n",
    "        article = scrape_articles(driver)\n",
    "        # set_filters(driver)\n",
    "        # all_cars = scrape_cars(driver)\n",
    "   \n",
    "    finally:\n",
    "        close_driver(driver)  # always close even if error\n",
    "    # return pd.DataFrame(all_cars)\n",
    "    return article\n",
    "\n",
    "article = main(BASE_URL)\n",
    "# cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6506b4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 5508 transfer news scrapped.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total of {len(article)} transfer news scrapped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097835b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
